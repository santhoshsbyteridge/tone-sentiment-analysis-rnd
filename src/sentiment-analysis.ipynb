{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "# Audio Sentiment Analysis\n",
    "\n",
    "The aim of this challenge is to read the audio (.wav) files and classify them into 3 sentiments (Positive, Neutral, or Negative).\n",
    "\n",
    "Sentiments:-\n",
    "- Positive\n",
    "- Negative\n",
    "- Neutral\n",
    "\n",
    "We will be applying following Ensemble Algorithms:-\n",
    "\n",
    "- NN with Tensorflow\n",
    "\n",
    "# Reading & Understanding Data\n",
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy pandas matplotlib seaborn scikit-learn librosa ipython scikit-image tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import sklearn.metrics as skm\n",
    "import sklearn.model_selection as skms\n",
    "import sklearn.preprocessing as skp\n",
    "import random, os\n",
    "import librosa, IPython\n",
    "import librosa.display as lplt\n",
    "from skimage.io import imread\n",
    "seed = 12\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "### Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "trainPath = './datasets/TRAIN/'\n",
    "testPath = './datasets/TEST/'\n",
    "df_base = pd.read_csv('./datasets/TRAIN.csv')\n",
    "df_base.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "### About the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"Dataset has\",df_base.shape[0],\"samples\")\n",
    "print(\"Count of Positive and Negative samples\")\n",
    "df_base['Class'].value_counts().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sample_rate = 44100\n",
    "def loadAudio(fp):\n",
    "    return librosa.load(fp, res_type='kaiser_fast', duration=2.5, offset=0.5, sr=sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "### MelSpec -> Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def scanFeatures(path, avgFeat=0):\n",
    "    features = []\n",
    "    minFeat = sys.maxsize\n",
    "    maxFeat = 0\n",
    "    files = sorted(os.listdir(path))\n",
    "    print(\"Scanning\", path)\n",
    "\n",
    "    for i, fp in enumerate(files):\n",
    "        X, sr = loadAudio(os.path.join(path, fp))\n",
    "\n",
    "        f = librosa.feature.melspectrogram(y=X, sr=sample_rate)\n",
    "        f = librosa.amplitude_to_db(f, ref=np.max)\n",
    "\n",
    "        shapeY = f.shape[1]\n",
    "        if shapeY < minFeat:\n",
    "            minFeat = shapeY\n",
    "\n",
    "        if shapeY > maxFeat:\n",
    "            maxFeat = shapeY\n",
    "\n",
    "        features.append(f)\n",
    "    if avgFeat == 0:\n",
    "        avgFeat = int((minFeat+maxFeat)/2)\n",
    "    feat_mat = np.zeros((len(files), f.shape[0], avgFeat))\n",
    "    for i, x in enumerate(features):\n",
    "        xWidth = min(x.shape[1],avgFeat)\n",
    "        feat_mat[i, :, :xWidth] = x[:,:xWidth]\n",
    "    return feat_mat, files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "f_dim = 128\n",
    "train_data, train_files = scanFeatures(trainPath, f_dim)\n",
    "test_data, test_files = scanFeatures(testPath, train_data.shape[1])\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "### MelSpec -> Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def saveImg(f, fp):\n",
    "    f = np.flip(f, axis=0)\n",
    "    plt.figure()\n",
    "    plt.axis('off')\n",
    "    plt.imsave(fp, f, format='png')\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def saveFeatureToImage(path, saveDir, avgFeat=0):\n",
    "    global sample_rate\n",
    "    files = sorted(os.listdir(path))\n",
    "    print(\"Scanning\", path)\n",
    "\n",
    "    for i, fp in enumerate(files):\n",
    "        X, sr = loadAudio(os.path.join(path, fp))\n",
    "\n",
    "        f = librosa.feature.melspectrogram(y=X, sr=sample_rate)\n",
    "        f = librosa.amplitude_to_db(f, ref=np.max)\n",
    "\n",
    "        img = np.zeros((f.shape[0], avgFeat))\n",
    "        xWidth = min(f.shape[1],avgFeat)\n",
    "        img[:, :xWidth] = f[:,:xWidth]\n",
    "        fname = os.path.join(saveDir, fp.split('.')[0] + '.png')\n",
    "        saveImg(img, fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "f_dim = 128\n",
    "train_img_dir = './train_images'\n",
    "test_img_dir = './test_images'\n",
    "if not os.path.exists(train_img_dir):\n",
    "    os.mkdir(train_img_dir)\n",
    "    saveFeatureToImage(trainPath, train_img_dir, f_dim)\n",
    "if not os.path.exists(test_img_dir):\n",
    "    os.mkdir(test_img_dir)\n",
    "    saveFeatureToImage(testPath, test_img_dir, train_data.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def scanImgFeatures(path):\n",
    "    features = []\n",
    "    files = sorted(os.listdir(path))\n",
    "    for x in files:\n",
    "        fp = os.path.join(path, x)\n",
    "        img = imread(fp)[:,:,:3]/255.0\n",
    "        features.append(img)\n",
    "    return np.array(features), files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if os.path.exists(train_img_dir):\n",
    "    train_data_img, train_files_img = scanImgFeatures(train_img_dir)\n",
    "if os.path.exists(test_img_dir):\n",
    "    test_data_img, test_files_img = scanImgFeatures(test_img_dir)\n",
    "    plt.imshow(test_data_img[0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def getPathLabels(p):\n",
    "    return [df_base[df_base['Filename'] == x].iloc[0,1] for x in p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_labels = getPathLabels(train_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "audio_fp = './datasets/TRAIN/1.wav'\n",
    "audio_data, sr = loadAudio(audio_fp)\n",
    "audio_data, _ = librosa.effects.trim(audio_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# play sample file\n",
    "IPython.display.Audio(audio_data, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# plot sample file\n",
    "plt.figure(figsize=(15,5))\n",
    "lplt.waveplot(audio_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Default FFT window size\n",
    "n_fft = 2048 # window size\n",
    "hop_length = 512 # window hop length for STFT\n",
    "\n",
    "stft = librosa.stft(audio_data, n_fft=n_fft, hop_length=hop_length)\n",
    "stft_db = librosa.amplitude_to_db(stft, ref=np.max)\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "lplt.specshow(stft, sr=sr, x_axis='time', y_axis='hz')\n",
    "plt.colorbar()\n",
    "plt.title(\"Spectrogram with amplitude\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "lplt.specshow(stft_db, sr=sr, x_axis='time', y_axis='log', cmap='cool')\n",
    "plt.colorbar()\n",
    "plt.title(\"Spectrogram with decibel log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "melspec = librosa.feature.melspectrogram(y=audio_data, sr=sample_rate)\n",
    "melspec_db = librosa.amplitude_to_db(melspec, ref=np.max)\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "lplt.specshow(melspec, sr=sr, x_axis='time', y_axis='hz')\n",
    "plt.colorbar()\n",
    "plt.title(\"Spectrogram with amplitude\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "lplt.specshow(melspec_db, sr=sr, x_axis='time', y_axis='log', cmap='cool')\n",
    "plt.colorbar()\n",
    "plt.title(\"Spectrogram with decibel log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "# Data Preparation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "## Encode Genre Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# map labels to index\n",
    "label_index = dict()\n",
    "index_label = dict()\n",
    "for i, x in enumerate(df_base['Class'].unique()):\n",
    "    label_index[x] = i\n",
    "    index_label[i] = x\n",
    "print(label_index)\n",
    "print(index_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# update labels in df to index\n",
    "train_labels_idx = [label_index[l] for l in train_labels]\n",
    "train_labels_idx[::10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "# Split Train & Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# shuffle samples\n",
    "df_shuffle = df_base.sample(frac=1, random_state=seed).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# remove irrelevant columns\n",
    "df_shuffle.drop(['Filename'], axis=1, inplace=True)\n",
    "df_y = df_shuffle.pop('Class')\n",
    "\n",
    "# split into train dev and test\n",
    "y_train, y_test = skms.train_test_split(df_y, train_size=0.8, random_state=seed, stratify=df_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(f\"Train set has {y_train.shape[0]} records out of {len(df_shuffle)} which is {round(y_train.shape[0]/len(df_shuffle)*100)}%\")\n",
    "print(f\"Test set has {y_test.shape[0]} records out of {len(df_shuffle)} which is {round(y_test.shape[0]/len(df_shuffle)*100)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# stratified split check\n",
    "print(y_train.value_counts())\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# divide train_data into X_train and X_test\n",
    "X_train = train_data[y_train.index.tolist(), :, :]\n",
    "X_test = train_data[y_test.index.tolist(), :, :]\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# divide train_data_img into X_train_img and X_test_img\n",
    "X_train_img = train_data_img[y_train.index.tolist(), :, :]\n",
    "X_test_img = train_data_img[y_test.index.tolist(), :, :]\n",
    "X_test_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "y_train = np.array([train_labels_idx[x] for x in y_train.index.tolist()])\n",
    "y_test = np.array([train_labels_idx[x] for x in y_test.index.tolist()])\n",
    "y_train[::10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "## Scale the Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# scale features\n",
    "scaler = skp.MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train.reshape(-1, X_train.shape[-1])).reshape(X_train.shape)\n",
    "X_test = scaler.transform(X_test.reshape(-1, X_test.shape[-1])).reshape(X_test.shape)\n",
    "test_data = scaler.transform(test_data.reshape(-1, test_data.shape[-1])).reshape(test_data.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TF version:-\", tf.__version__)\n",
    "import keras as k\n",
    "from keras import backend as K\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "editable": false,
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "bestModelPath = './best_model.h5'\n",
    "ACCURACY_THRESHOLD = 0.98\n",
    "\n",
    "class myCallback(k.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('val_accuracy') > ACCURACY_THRESHOLD):\n",
    "            print(\"\\n\\nStopping training as we have reached %2.2f%% accuracy!\" %(ACCURACY_THRESHOLD*100))   \n",
    "            self.model.stop_training = True\n",
    "\n",
    "acc_callback = myCallback()\n",
    "\n",
    "\n",
    "def trainModel(model, epochs, optimizer, vb=1):\n",
    "    cbs = [#k.callbacks.ReduceLROnPlateau(patience=5, verbose=1), \n",
    "           k.callbacks.ModelCheckpoint(filepath=bestModelPath, monitor='val_loss', verbose=1, save_best_only=True)]\n",
    "    batch_size = 64\n",
    "    callback = myCallback()\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy']\n",
    "    )\n",
    "    return model.fit(X_train, y_train, \n",
    "#                      validation_data=(X_test, y_test), \n",
    "                     epochs=epochs, verbose=vb,\n",
    "                     validation_split=0.2,\n",
    "                     batch_size=batch_size, callbacks=cbs)\n",
    "\n",
    "def plotHistory(history):\n",
    "    print(\"Max. Validation Accuracy\",max(history.history[\"val_accuracy\"]))\n",
    "    pd.DataFrame(history.history).plot(figsize=(12,6))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_1 = k.models.Sequential([\n",
    "    k.layers.Conv1D(256, 8, padding='same', activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "#     k.layers.Conv1D(256, 8, padding='same', activation='relu'),\n",
    "    k.layers.BatchNormalization(),\n",
    "    k.layers.Dropout(0.2),\n",
    "    k.layers.MaxPooling1D(pool_size=(8)),\n",
    "    k.layers.Conv1D(128, 8, padding='same', activation='relu'),\n",
    "#     k.layers.Conv1D(128, 8, padding='same', activation='relu'),\n",
    "#     k.layers.Conv1D(128, 8, padding='same', activation='relu'),\n",
    "    k.layers.BatchNormalization(),\n",
    "    k.layers.Dropout(0.2),\n",
    "    k.layers.MaxPooling1D(pool_size=(5)),\n",
    "#     k.layers.Conv1D(64, 8, padding='same', activation='relu'),\n",
    "    k.layers.Conv1D(64, 8, padding='same', activation='relu'),\n",
    "    k.layers.BatchNormalization(),\n",
    "    k.layers.Flatten(),\n",
    "#     k.layers.Dense(64, activation='relu'),\n",
    "    k.layers.Dense(len(index_label), activation='softmax'),\n",
    "])\n",
    "print(model_1.summary())\n",
    "model_1_history = trainModel(model=model_1, epochs=50, optimizer='adam', vb=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plotHistory(model_1_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# evaluation\n",
    "test_loss, test_acc  = k.models.load_model(bestModelPath).evaluate(X_test, y_test, batch_size=128)\n",
    "print(\"The test Loss is :\",test_loss)\n",
    "print(\"The test Accuracy is :\",test_acc*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_2 = k.models.Sequential([\n",
    "    k.layers.Conv1D(256, 5, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    k.layers.BatchNormalization(),\n",
    "    k.layers.Dropout(0.3),\n",
    "    k.layers.MaxPooling1D(pool_size=(2)),\n",
    "    k.layers.Conv1D(128, 3, activation='relu'),\n",
    "    k.layers.BatchNormalization(),\n",
    "    k.layers.Dropout(0.3),\n",
    "    k.layers.MaxPooling1D(pool_size=(3)),\n",
    "    k.layers.Conv1D(64, 3, activation='relu'),\n",
    "    k.layers.BatchNormalization(),\n",
    "    k.layers.Flatten(),\n",
    "    k.layers.Dense(32, activation='relu'),\n",
    "    k.layers.Dense(len(index_label), activation='softmax'),\n",
    "])\n",
    "print(model_2.summary())\n",
    "model_2_history = trainModel(model=model_2, epochs=100, optimizer='adam', vb=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plotHistory(model_2_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# evaluation\n",
    "test_loss, test_acc  = k.models.load_model(bestModelPath).evaluate(X_test, y_test, batch_size=128)\n",
    "print(\"The test Loss is :\",test_loss)\n",
    "print(\"The test Accuracy is :\",test_acc*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_3 = k.models.Sequential([\n",
    "    k.layers.Bidirectional(k.layers.LSTM(256, return_sequences=True), input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "\n",
    "    k.layers.Bidirectional(k.layers.LSTM(128, return_sequences=False)),\n",
    "\n",
    "    k.layers.Dense(64, activation='relu'),\n",
    "    k.layers.Dropout(0.2),\n",
    "    k.layers.Dense(64, activation='relu'),\n",
    "    k.layers.Dropout(0.2),\n",
    "    k.layers.Dense(32, activation='relu'),\n",
    "    k.layers.Dense(len(index_label), activation='softmax'),\n",
    "])\n",
    "print(model_3.summary())\n",
    "model_3_history = trainModel(model=model_3, epochs=100, optimizer='rmsprop', vb=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plotHistory(model_3_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# evaluation\n",
    "test_loss, test_acc  = k.models.load_model(bestModelPath).evaluate(X_test, y_test, batch_size=128)\n",
    "print(\"The test Loss is :\",test_loss)\n",
    "print(\"The test Accuracy is :\",test_acc*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# make features 3D with last dim as 1 for 1DConv\n",
    "X_train = np.expand_dims(X_train, axis=3)\n",
    "X_test = np.expand_dims(X_test, axis=3)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_4 = k.models.Sequential([\n",
    "    k.layers.Conv2D(256, (5,5), activation='relu', input_shape=(X_train.shape[1], X_train.shape[2], 1)),\n",
    "    k.layers.BatchNormalization(),\n",
    "    k.layers.MaxPooling2D(pool_size=(2)),\n",
    "    k.layers.Dropout(0.3),\n",
    "    k.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    k.layers.BatchNormalization(),\n",
    "    k.layers.MaxPooling2D(pool_size=(2)),\n",
    "    k.layers.Dropout(0.3),\n",
    "    k.layers.Conv2D(64, (3,3), padding='valid', activation='relu'),\n",
    "    k.layers.BatchNormalization(),\n",
    "    k.layers.Flatten(),\n",
    "    k.layers.Dense(64, activation='relu'),\n",
    "    k.layers.Dense(len(index_label), activation='softmax'),\n",
    "\n",
    "])\n",
    "print(model_4.summary())\n",
    "model_4_history = trainModel(model=model_4, epochs=50, optimizer='adam', vb=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plotHistory(model_4_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# evaluation\n",
    "test_loss, test_acc  = k.models.load_model(bestModelPath).evaluate(X_test, y_test, batch_size=128)\n",
    "print(\"The test Loss is :\",test_loss)\n",
    "print(\"The test Accuracy is :\",test_acc*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "inputShape = (X_train.shape[1], X_train.shape[2], 1)\n",
    "model_5 = k.models.Sequential([\n",
    "    k.layers.TimeDistributed(k.layers.Conv1D(256, 5), input_shape=inputShape),\n",
    "    k.layers.TimeDistributed(k.layers.BatchNormalization()),\n",
    "    k.layers.TimeDistributed(k.layers.MaxPooling1D((2))),\n",
    "    k.layers.TimeDistributed(k.layers.Dropout(0.3)),\n",
    "\n",
    "    k.layers.TimeDistributed(k.layers.Conv1D(128, 3), input_shape=inputShape),\n",
    "    k.layers.TimeDistributed(k.layers.BatchNormalization()),\n",
    "    k.layers.TimeDistributed(k.layers.MaxPooling1D((2))),\n",
    "    k.layers.TimeDistributed(k.layers.Dropout(0.3)),\n",
    "    k.layers.TimeDistributed(k.layers.Flatten())\n",
    "\n",
    "], name=\"conv_3d7\")\n",
    "\n",
    "model_5.add(k.layers.Bidirectional(k.layers.LSTM(256, return_sequences=True)))\n",
    "model_5.add(k.layers.Dropout(0.3))\n",
    "\n",
    "model_5.add(k.layers.Bidirectional(k.layers.LSTM(128)))\n",
    "model_5.add(k.layers.Dropout(0.3))\n",
    "\n",
    "model_5.add(k.layers.Dense(64, activation='relu'))\n",
    "model_5.add(k.layers.Dropout(0.3))\n",
    "\n",
    "model_5.add(k.layers.Dense(len(index_label), activation='softmax'))\n",
    "\n",
    "print(model_5.summary())\n",
    "model_5_history = trainModel(model=model_5, epochs=100, optimizer='adam', vb=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plotHistory(model_5_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# evaluation\n",
    "test_loss, test_acc  = k.models.load_model(bestModelPath).evaluate(X_test, y_test, batch_size=128)\n",
    "print(\"The test Loss is :\",test_loss)\n",
    "print(\"The test Accuracy is :\",test_acc*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "## Model using Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "modelPath = './best_model.hdf5'\n",
    "ACCURACY_THRESHOLD = 0.95\n",
    "\n",
    "class myCallback(k.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('val_accuracy') > ACCURACY_THRESHOLD):\n",
    "            print(\"\\n\\nStopping training as we have reached %2.2f%% accuracy!\" %(ACCURACY_THRESHOLD*100))   \n",
    "            self.model.stop_training = True\n",
    "\n",
    "acc_callback = myCallback()\n",
    "\n",
    "cbs = [#k.callbacks.ReduceLROnPlateau(patience=3, verbose=1), \n",
    "       k.callbacks.ModelCheckpoint(filepath=modelPath, monitor='val_loss', verbose=1, save_best_only=True)]\n",
    "\n",
    "def trainImgModel(model, epochs, optimizer, vb=1):\n",
    "    batch_size = 64\n",
    "    callback = myCallback()\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics='accuracy'\n",
    "    )\n",
    "    return model.fit(X_train_img, y_train, \n",
    "                     validation_data=(X_test_img, y_test), epochs=epochs, verbose=vb,\n",
    "                     batch_size=batch_size, callbacks=cbs)\n",
    "\n",
    "def plotHistory(history):\n",
    "    print(\"Max. Validation Accuracy\",max(history.history[\"val_accuracy\"]))\n",
    "    pd.DataFrame(history.history).plot(figsize=(12,6))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_6 = k.models.Sequential([\n",
    "    k.layers.Conv2D(256, 3, activation='relu', input_shape=(128, 128, 3)),\n",
    "    k.layers.BatchNormalization(),\n",
    "    k.layers.MaxPooling2D(pool_size=(2)),\n",
    "    k.layers.Dropout(0.2),\n",
    "    k.layers.Conv2D(128, 3, activation='relu'),\n",
    "    k.layers.BatchNormalization(),\n",
    "    k.layers.MaxPooling2D(pool_size=(2)),\n",
    "    k.layers.Dropout(0.2),\n",
    "    k.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    k.layers.BatchNormalization(),\n",
    "    k.layers.Flatten(),\n",
    "    k.layers.Dense(64, activation='relu'),\n",
    "    k.layers.Dense(len(index_label), activation='softmax'),\n",
    "\n",
    "])\n",
    "print(model_6.summary())\n",
    "model_6_history = trainImgModel(model=model_6, epochs=100, optimizer='rmsprop', vb=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plotHistory(model_6_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# model evaluation\n",
    "test_loss, test_acc  = k.models.load_model(bestModelPath).evaluate(X_test_img, y_test, batch_size=128)\n",
    "print(\"The test Loss is :\",test_loss)\n",
    "print(\"The test Accuracy is :\",test_acc*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# test_data = np.expand_dims(test_data, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "predictions = np.argmax(k.models.load_model(bestModelPath).predict(test_data_img), axis=1)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_sub = pd.DataFrame({\n",
    "    'Filename': test_files,\n",
    "    'Class': list(map(lambda x:index_label[x], predictions))\n",
    "})\n",
    "df_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "submission_file = 'submission.csv'\n",
    "df_sub.to_csv(submission_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1099611,
     "sourceId": 1854274,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30042,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
